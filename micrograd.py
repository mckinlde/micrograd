# following along with Andrej's Jyupter Notebook

# micrograd is an automatic gradient engine, it implements backpropogation

# backpropogation tunes weights to iteratively tune the loss function

# micrograd allows you to build out mathematical expressions

# gradient is a fancy word for the derivative of F(x) with respect to G(x)

